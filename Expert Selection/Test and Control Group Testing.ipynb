{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions and Run Initial Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\austen.moore\\AppData\\Local\\Temp\\ipykernel_21904\\1449088947.py:20: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query,cnxn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee</th>\n",
       "      <th>TenureGroup</th>\n",
       "      <th>Date</th>\n",
       "      <th>HoursWorked</th>\n",
       "      <th>Sessions</th>\n",
       "      <th>Total_Resolution_Time</th>\n",
       "      <th>Total_Accepted</th>\n",
       "      <th>Total_Eligible</th>\n",
       "      <th>Helix_Searches</th>\n",
       "      <th>Helix_Sessions</th>\n",
       "      <th>CXP_Prob_Sum</th>\n",
       "      <th>CXP_Prob_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>512839</td>\n",
       "      <td>180+</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>577970</td>\n",
       "      <td>121-180</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>9.34</td>\n",
       "      <td>15.00</td>\n",
       "      <td>19,742.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10.86</td>\n",
       "      <td>21.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>577970</td>\n",
       "      <td>121-180</td>\n",
       "      <td>2023-07-21</td>\n",
       "      <td>6.97</td>\n",
       "      <td>16.00</td>\n",
       "      <td>13,457.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.20</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>577970</td>\n",
       "      <td>121-180</td>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>7.78</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15,269.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11.24</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>577970</td>\n",
       "      <td>121-180</td>\n",
       "      <td>2023-07-24</td>\n",
       "      <td>8.89</td>\n",
       "      <td>24.00</td>\n",
       "      <td>14,888.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>14.71</td>\n",
       "      <td>29.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Employee TenureGroup        Date  HoursWorked  Sessions  \\\n",
       "0    512839        180+        None          NaN       NaN   \n",
       "1    577970     121-180  2023-08-21         9.34     15.00   \n",
       "2    577970     121-180  2023-07-21         6.97     16.00   \n",
       "3    577970     121-180  2023-06-22         7.78     20.00   \n",
       "4    577970     121-180  2023-07-24         8.89     24.00   \n",
       "\n",
       "   Total_Resolution_Time  Total_Accepted  Total_Eligible  Helix_Searches  \\\n",
       "0                    NaN             NaN             NaN               0   \n",
       "1              19,742.00            0.00           13.00               9   \n",
       "2              13,457.00            0.00           14.00               1   \n",
       "3              15,269.00            1.00           18.00               2   \n",
       "4              14,888.00            0.00           20.00               5   \n",
       "\n",
       "   Helix_Sessions  CXP_Prob_Sum  CXP_Prob_Count  \n",
       "0               0           NaN             NaN  \n",
       "1               1         10.86           21.00  \n",
       "2               1         10.20           20.00  \n",
       "3               2         11.24           22.00  \n",
       "4               2         14.71           29.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 10\n",
    "\n",
    "def read_query_file(fileName):\n",
    "    file = open(fileName,'r')\n",
    "    string = file.read()\n",
    "    file.close()\n",
    "    return string\n",
    "\n",
    "def run_query(query):\n",
    "    cnxn = pyodbc.connect('DSN=edp-workbench-cshub', autocommit=True)\n",
    "    df = pd.read_sql_query(query,cnxn)\n",
    "    cnxn.close()\n",
    "    return df\n",
    "\n",
    "df = run_query(read_query_file('SQL\\SamplingTest\\KeyMetrics_ForGroupSelection.SQL'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CXP_Prob_Count'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build out the metrics from the Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SP100'] = df['Total_Accepted']/df['Total_Eligible']\n",
    "df['CXP_Score']=df['CXP_Prob_Sum']/df['CXP_Prob_Count']\n",
    "df['Sessions Per Hour'] = df['Sessions']/df['HoursWorked']\n",
    "df['CRT']= df['Total_Resolution_Time']/df['Sessions']\n",
    "df['Searches Per Session']= df['Helix_Searches']/df['Sessions']\n",
    "df['%Sessions With Search']= df['Helix_Sessions']/df['Sessions']\n",
    "df=df.join(pd.get_dummies(df['TenureGroup']))\n",
    "employees_df = df[['Employee','TenureGroup']].copy().drop_duplicates(subset='Employee')\n",
    "display(employees_df)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Sample Size by Tenure Group\n",
    "Using the current number of experts find the number of samples needed in each group to be representative of the general population at Orlando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 30\n",
    "sample_size_df=pd.pivot_table(df.copy(),index='TenureGroup',values='Employee',aggfunc=lambda x: len(x.unique()),margins=True,)\n",
    "sample_size_df['Total Employees']=sample_size_df['Employee']\n",
    "del sample_size_df['Employee']\n",
    "sample_size_df['% of Employees'] = sample_size_df['Total Employees']/sample_size_df['Total Employees'].loc['All']\n",
    "sample_size_df['n Employees'] = (sample_size_df['% of Employees']* SAMPLE_SIZE).round()\n",
    "\n",
    "sample_size_df=sample_size_df.iloc[:-1]\n",
    "display(sample_size_df.sum())\n",
    "display(sample_size_df)\n",
    "\n",
    "del SAMPLE_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "1. Creates representative samples\n",
    "2. Tests those samples to see if they have a meaningful effect on the metric\n",
    "    1. Runs an OLS on the sample to see if they have high p val for the metric. If they have a low value for all metrics they are saved as a good possible sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_VAL_FLOOR = .5\n",
    "SAMPLES = 10000\n",
    "\n",
    "SelectionMetrics = ['CRT','%Sessions With Search','SP100','CXP_Score']\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Members']+SelectionMetrics)\n",
    "\n",
    "# Build test dataframe dft and get groups setup\n",
    "groups = sample_size_df.index.to_list()\n",
    "dft = df[['Employee']+SelectionMetrics+groups].copy()\n",
    "dft['Constant']=1\n",
    "dft = dft.replace({np.inf : np.nan,np.inf : np.nan})\n",
    "dft= dft.dropna()\n",
    "\n",
    "# Make a loop to run this a bunch\n",
    "for run in range(1,SAMPLES):\n",
    "    # creates a list for the sampled employes\n",
    "    # then adds the correct number of samples from each group to it\n",
    "    sample_group = []\n",
    "    for group in groups:\n",
    "        sample_df = employees_df[employees_df['TenureGroup']==group]\n",
    "        sample_group= sample_group+ sample_df['Employee'].sample(\n",
    "            n=int(sample_size_df.loc[group]['n Employees'])\n",
    "            ,replace=False\n",
    "            ,random_state=run\n",
    "            ).tolist()\n",
    "    del group\n",
    "    \n",
    "    # Flag the employees in the group\n",
    "    dft['TestSample']=(dft['Employee'].isin(sample_group)).astype(int)\n",
    "    \n",
    "    # Make sure the p vals are high enough to assume no statistical significance\n",
    "    # Also added a lower and upper bound to make sure it could be positive or negative\n",
    "    p_val_list = []\n",
    "    for y in SelectionMetrics:\n",
    "        model = sm.OLS(endog=dft[y].copy(),exog=dft.copy()[groups+['TestSample','Constant']]).fit().summary2().tables[1]\n",
    "        p_val = model['P>|t|'].loc['TestSample']\n",
    "        lower = model['[0.025'].loc['TestSample']\n",
    "        upper = model['0.975]'].loc['TestSample']\n",
    "        if p_val >= P_VAL_FLOOR and lower<0 and upper>0:\n",
    "            p_val_list.append(p_val)\n",
    "        del p_val, y\n",
    "    # add sample group to results list if the results were not significant\n",
    "    if len(p_val_list)==len(SelectionMetrics):\n",
    "        current_result = dict(zip(['Members']+SelectionMetrics,[[sample_group]]+p_val_list))\n",
    "        results_df=pd.concat([results_df,pd.DataFrame(current_result,index=[run])])\n",
    "    del sample_group, p_val_list, dft['TestSample'], sample_df\n",
    "\n",
    "del dft, SAMPLES, P_VAL_FLOOR, run, groups, \n",
    "\n",
    "results_df\n",
    "# results_df.to_excel('Unbiased Sample Selections.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find and display subsets that do not have any duplicate members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_excel('Unbiased Sample Selections.xlsx')\n",
    "# SelectionMetrics = ['CRT','%Sessions With Search','SP100','CXP_Score']\n",
    "results_df['TotalPVal']=0\n",
    "for metric in SelectionMetrics:\n",
    "    results_df['TotalPVal'] = results_df['TotalPVal']+results_df[metric]\n",
    "results_df['AvgPVal']= results_df['TotalPVal']/len(SelectionMetrics)\n",
    "\n",
    "del metric\n",
    "for row1 in range(len(results_df['Members'])):\n",
    "    for row2 in range(1,len(results_df['Members'])):\n",
    "        duplicates = 0\n",
    "        for item in results_df['Members'].iloc[row1]:\n",
    "            if item in results_df['Members'].iloc[row2]: \n",
    "                duplicates=duplicates+1\n",
    "                display(item)\n",
    "        if duplicates == 0:\n",
    "            display(pd.concat([results_df.iloc[[row1]],results_df.iloc[[row2]]]))\n",
    "del row1, row2, duplicates, item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel('Unbiased Sample Selections.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changes\n",
    "1. Drop Sessions Per Hour\n",
    "2. Get SP100 and CXP from Brian Vickers\n",
    "3. Check on Helx Search Ravi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
