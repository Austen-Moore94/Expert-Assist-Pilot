{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "def file_to_string(fileName):\n",
    "    file = open(fileName,'r')\n",
    "    string = file.read()\n",
    "    file.close()\n",
    "    return string.replace('$DATE$','2023-08-28')\n",
    "\n",
    "def timestamp():\n",
    "    return datetime.now().strftime('%Y-%m-%d %I:%M:%S %p')\n",
    "\n",
    "def run_query(query):\n",
    "    print(\"Query Start \" + timestamp())\n",
    "    cnxn = pyodbc.connect('DSN=edp-workbench-cshub', autocommit=True)\n",
    "    df = pd.read_sql_query(query,cnxn)\n",
    "    cnxn.close()\n",
    "    print(\"Query End \" + timestamp())\n",
    "    return df\n",
    "    \n",
    "def add_conditionals(df):\n",
    "    df = df.copy()\n",
    "    df['Date']=pd.to_datetime(df['Date'])\n",
    "    \n",
    "    df['1st Reactive ExAsst Group'] = (df['Employee'].isin((\n",
    "        581139, 569375, 575996, 547655, 573190, 573276,\n",
    "        572909, 573192, 573585, 573573, 572815, 552121,\n",
    "        576911, 572247, 364717, 426097, 554487, 575731,\n",
    "        576565, 577073, 577246, 579162, 580895, 580911,\n",
    "        581015, 581145, 581275\n",
    "        ))).astype(int)\n",
    "    \n",
    "    df['2nd Reactive ExAsst Group'] = (df['Employee'].isin((\n",
    "        548026, 548646, 579630, 550446, 569153, 578299\n",
    "    ))).astype(int)\n",
    "\n",
    "    df['Proactive ExAsst Group'] = (df['Employee'].isin((\n",
    "        573190, 573276, 572909, 573192, 573585,\n",
    "        573573, 572815, 552121, 576911, 572247\n",
    "        ))).astype(int)\n",
    "\n",
    "    df['After Reactive  ExAsst Launch']=(df['Date']>=datetime(2023,9,25)).astype(int)\n",
    "    df['After Proactive ExAsst Launch']=(df['Date']>=datetime(2023,11,10)).astype(int)\n",
    "    df['Has Proactive'] = df['Proactive ExAsst Group'] * df['After Proactive ExAsst Launch']\n",
    "    \n",
    "    df['Has Reactive'] = np.sign((\n",
    "        df['After Reactive  ExAsst Launch'] * df['1st Reactive ExAsst Group']\n",
    "        +\n",
    "        df['After Proactive ExAsst Launch'] * df['2nd Reactive ExAsst Group']\n",
    "        ))\n",
    "\n",
    "    df['Test Group For This Period'] = np.select(condlist = [df['Has Proactive']==1,df['Has Reactive']==1], choicelist = ['Proactive','Reactive'],default='Control')\n",
    "    df['Test Group After Launch'] = np.select(\n",
    "        condlist = [\n",
    "            df['Proactive ExAsst Group']==1,\n",
    "            np.logical_and(\n",
    "                np.logical_or(df['1st Reactive ExAsst Group']==1,df['2nd Reactive ExAsst Group']==1)\n",
    "                ,df['Proactive ExAsst Group']==0)\n",
    "            ],\n",
    "        choicelist = ['Proactive','Reactive'],default='Control')\n",
    "\n",
    "    df['Day'] = df['Date'].dt.weekday\n",
    "    days = {0:'Monday',1:'Tuesday',2:'Wednesday',3:'Thursday',4:'Friday',5:'Saturday',6:'Sunday'}\n",
    "    for day in days:\n",
    "        df[days[day]]=(df['Day']==day).astype(int)\n",
    "    df['Week']=df['Date'].dt.isocalendar().week\n",
    "    df['Weeks Ago'] = df['Week'].astype(int).max() - df['Week'].astype(int)\n",
    "    for week in df['Week'].unique():\n",
    "        df['Week '+str(week)]= (df['Week']==week).astype(int)\n",
    "    # for queue in df['TaskQueue'].unique():\n",
    "    #     df[queue] = (df['TaskQueue']==queue).astype(int)\n",
    "    df['Constant'] =1\n",
    "    return df\n",
    "\n",
    "def add_metrics(df):\n",
    "    df = df.copy()\n",
    "    df['AHT'] = df['Total_Resolution_Time']/df['Sessions']\n",
    "    df['HERO'] = df['HERO_XR_Score']/df['HERO_XR_Count']\n",
    "    df['SP100'] = df['Total_Accepted']/df['Total_Eligible']\n",
    "    df['Transfers'] = df['Transfer_Count']/df['Transfer_Score']\n",
    "    df['Constant'] =1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = run_query(file_to_string('DailyMetrics.SQL'))\n",
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricList = ['Sessions','AHT','HERO','SP100']\n",
    "metric_Inputs = ['Sessions','Total_Resolution_Time''HERO_XR_Score','HERO_XR_Count', 'Transfer_Score', 'Transfer_Count',\n",
    "              'Helix_Searches', 'Helix_Sessions' 'Total_Eligible','Total_Accepted']\n",
    "test_df = add_conditionals(df_daily)\n",
    "test_df = add_metrics(test_df)\n",
    "\n",
    "test_df = test_df.dropna()\n",
    "test_df.info(verbose=False)\n",
    "display(test_df.head(5))\n",
    "for metric in metricList:\n",
    "    display(sm.OLS(\n",
    "        endog = test_df[metric],\n",
    "        exog = test_df[['Has Proactive','Has Reactive','Weeks Ago','Constant']]\n",
    "        ).fit().summary())\n",
    "    px.box(test_df,y=metric,color='Test Group For This Period', title=metric).show()\n",
    "    graph_df = pd.pivot_table(test_df[test_df['Test Group After Launch']!='Control'].copy(),values=metric,columns='Test Group After Launch',index='Date')\n",
    "    px.line(graph_df,title=metric).show()\n",
    "    del graph_df\n",
    "del test_df, metricList, metric_Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = add_conditionals(df_daily)\n",
    "test_df = add_metrics(test_df)\n",
    "\n",
    "test_df = test_df.dropna()\n",
    "# display(test_df.head(5))\n",
    "\n",
    "display(sm.OLS(\n",
    "    endog = test_df['AHT'],\n",
    "    exog = test_df[['Has Proactive','Weeks Ago','Constant']]\n",
    "    ).fit().summary())\n",
    "del test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Start 2023-12-05 12:44:56 PM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\austen.moore\\AppData\\Local\\Temp\\ipykernel_14772\\3531319944.py:24: UserWarning:\n",
      "\n",
      "pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query End 2023-12-05 12:45:15 PM\n"
     ]
    }
   ],
   "source": [
    "df_sessions = run_query(file_to_string('AHT And Sales.SQL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Handle Time</td>   <th>  R-squared:         </th>  <td>   0.072</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.071</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   223.8</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 05 Dec 2023</td> <th>  Prob (F-statistic):</th>  <td>2.16e-276</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:09:12</td>     <th>  Log-Likelihood:    </th> <td>-1.4419e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 17435</td>      <th>  AIC:               </th>  <td>2.884e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 17428</td>      <th>  BIC:               </th>  <td>2.884e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Constant</th>               <td> 1119.8022</td> <td>   33.393</td> <td>   33.534</td> <td> 0.000</td> <td> 1054.349</td> <td> 1185.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Has Proactive</th>          <td> -141.8607</td> <td>   24.869</td> <td>   -5.704</td> <td> 0.000</td> <td> -190.607</td> <td>  -93.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Offered</th>                <td>  294.8686</td> <td>   14.946</td> <td>   19.729</td> <td> 0.000</td> <td>  265.573</td> <td>  324.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Accepted</th>               <td>  699.8320</td> <td>   29.431</td> <td>   23.779</td> <td> 0.000</td> <td>  642.144</td> <td>  757.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Weeks Ago</th>              <td>  -19.3751</td> <td>    2.986</td> <td>   -6.489</td> <td> 0.000</td> <td>  -25.228</td> <td>  -13.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VZN_MTS_Bundle_EN_2233</th> <td>  -85.3605</td> <td>   28.156</td> <td>   -3.032</td> <td> 0.002</td> <td> -140.549</td> <td>  -30.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VZN_Onboarding_2628</th>    <td>   90.9916</td> <td>   33.650</td> <td>    2.704</td> <td> 0.007</td> <td>   25.034</td> <td>  156.949</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>9179.172</td> <th>  Durbin-Watson:     </th> <td>   1.966</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>97903.726</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.312</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>13.649</td>  <th>  Cond. No.          </th> <td>    42.2</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            Handle Time   R-squared:                       0.072\n",
       "Model:                            OLS   Adj. R-squared:                  0.071\n",
       "Method:                 Least Squares   F-statistic:                     223.8\n",
       "Date:                Tue, 05 Dec 2023   Prob (F-statistic):          2.16e-276\n",
       "Time:                        13:09:12   Log-Likelihood:            -1.4419e+05\n",
       "No. Observations:               17435   AIC:                         2.884e+05\n",
       "Df Residuals:                   17428   BIC:                         2.884e+05\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Constant                1119.8022     33.393     33.534      0.000    1054.349    1185.256\n",
       "Has Proactive           -141.8607     24.869     -5.704      0.000    -190.607     -93.114\n",
       "Offered                  294.8686     14.946     19.729      0.000     265.573     324.165\n",
       "Accepted                 699.8320     29.431     23.779      0.000     642.144     757.520\n",
       "Weeks Ago                -19.3751      2.986     -6.489      0.000     -25.228     -13.522\n",
       "VZN_MTS_Bundle_EN_2233   -85.3605     28.156     -3.032      0.002    -140.549     -30.172\n",
       "VZN_Onboarding_2628       90.9916     33.650      2.704      0.007      25.034     156.949\n",
       "==============================================================================\n",
       "Omnibus:                     9179.172   Durbin-Watson:                   1.966\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            97903.726\n",
       "Skew:                           2.312   Prob(JB):                         0.00\n",
       "Kurtosis:                      13.649   Cond. No.                         42.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = add_conditionals(df_sessions.copy())\n",
    "\n",
    "\n",
    "for queue in test_df['TaskQueue'].unique():\n",
    "    test_df[queue] = (test_df['TaskQueue']==queue).astype(int)\n",
    "\n",
    "\n",
    "display(sm.OLS(\n",
    "    endog = test_df['Handle Time'],\n",
    "    exog = test_df[[ 'Constant', 'Has Proactive',\n",
    "                    'Offered', 'Accepted', 'Weeks Ago',\n",
    "                    'VZN_MTS_Bundle_EN_2233', 'VZN_Onboarding_2628'\n",
    "                     ]]\n",
    "    ).fit().summary())\n",
    "\n",
    "del test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
