{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions and Run Initial Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "def file_to_string(fileName):\n",
    "    file = open(fileName,'r')\n",
    "    string = file.read()\n",
    "    file.close()\n",
    "    return string\n",
    "\n",
    "def run_query(query):\n",
    "    cnxn = pyodbc.connect('DSN=edp-workbench-cshub', autocommit=True)\n",
    "    df = pd.read_sql_query(query,cnxn)\n",
    "    cnxn.close()\n",
    "    return df\n",
    "    \n",
    "def timestamp():\n",
    "    return datetime.now().strftime('%Y-%m-%d %I:%M:%S %p')\n",
    "\n",
    "def add_conditionals(df):\n",
    "    df = df.copy()\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Day'] = df['Date'].dt.weekday\n",
    "    # days = {0:'Monday',1:'Tuesday',2:'Wednesday',3:'Thursday',4:'Friday',5:'Saturday',6:'Sunday'}\n",
    "    # for day in days:\n",
    "    #     df[days[day]]=(df['Day']==day).astype(int)\n",
    "    df['Week']=df['Date'].dt.isocalendar().week\n",
    "    # df['Weeks Ago'] = df['Week'].astype(int).max() - df['Week'].astype(int)\n",
    "    for week in df['Week'].unique():\n",
    "        df['Week '+str(week)]= (df['Week']==week).astype(int)\n",
    "    df['Constant'] =1\n",
    "    return df\n",
    "\n",
    "def add_metrics(df):\n",
    "    df = df.copy()\n",
    "    df['AHT'] = df['Total_Resolution_Time']/df['Sessions']\n",
    "    df['HERO'] = df['HERO_XR_Score']/df['HERO_XR_Count']\n",
    "    df['SP100'] = df['Total_Accepted']/df['Total_Eligible']\n",
    "    df['Transfers'] = df['Transfer_Score']/df['Sessions']\n",
    "    df['Constant'] =1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\austen.moore\\AppData\\Local\\Temp\\ipykernel_16304\\1424633913.py:20: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query,cnxn)\n"
     ]
    }
   ],
   "source": [
    "test_df = run_query(\n",
    "    \"\"\"SELECT\n",
    "            AT_TIMEZONE(\n",
    "                FROM_ISO8601_TIMESTAMP(\n",
    "                    REPLACE(\n",
    "                        TRIM(element_at(VHE.edp_raw_data_map, 'ExtraData_endRequestTime')),\n",
    "                        ' ','T'))\n",
    "            ,'America/Chicago') as \"endRequestTime\",\n",
    "            element_at(VHE.edp_raw_data_map, 'ExtraData_endRequestTime') RawTimestamp_End,\n",
    "            \n",
    "            AT_TIMEZONE(\n",
    "                FROM_ISO8601_TIMESTAMP(\n",
    "                    REPLACE(\n",
    "                        TRIM(element_at(VHE.edp_raw_data_map, 'ExtraData_startRequestTime')),\n",
    "                        ' ','T'))\n",
    "            ,'America/Chicago') as \"StartRequestTime\",\n",
    "            element_at(VHE.edp_raw_data_map, 'ExtraData_startRequestTime') RawTimestamp_Start,\n",
    "        TRY(CAST(element_at(VHE.edp_raw_data_map, 'ExtraData_agentId') AS BIGINT)) as \"Employee\"\n",
    "    FROM \n",
    "        hive.care.l1_verizon_home_events VHE\n",
    "    WHERE 1=1\n",
    "        AND element_at(VHE.edp_raw_data_map, '_header_eventContext_producer') = 'eip-ingestion-data-science'\n",
    "        AND element_at(VHE.edp_raw_data_map, 'Identities_messageSid') IS NOT NULL\n",
    "        AND element_at(VHE.edp_raw_data_map, 'Name') = 'RequestSummaryVoice'\n",
    "        AND element_at(VHE.edp_raw_data_map, 'Scope')='GenerativeAISearchBotVoice'\n",
    "        AND DATE(edp_updated_date) >= DATE('2023-12-04')\n",
    "    LIMIT 100\n",
    "\"\"\"\n",
    "        )\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = run_query(file_to_string('DailyMetrics.SQL'))\n",
    "display(dfp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "1. Creates representative samples\n",
    "2. Tests those samples if they are within a number of standard deviations from the test group. If so adds them to a list for further examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = add_conditionals(dfp.copy())\n",
    "employees\n",
    "\n",
    "# Define Metrics and Groups Being Tested\n",
    "mainMetrics=['Sessions','AHT','SP100','HERO','Transfers']\n",
    "testGroup = [\"Test Members\",\"Control Members\"]\n",
    "\n",
    "\n",
    "# Get yearly metrics\n",
    "results_pivot = pd.pivot_table(\n",
    "    dfp.copy(),\n",
    "    index='Employee',\n",
    "    values=['Total_Accepted','Total_Eligible','HERO_XR_Score','HERO_XR_Count', \n",
    "            'Transfer_Score', 'Transfer_Count','Total_Resolution_Time','Sessions'],\n",
    "            aggfunc=np.sum)\n",
    "\n",
    "# AddMetrics\n",
    "results_pivot = add_metrics(results_pivot)\n",
    "results_pivot = results_pivot[mainMetrics]\n",
    "\n",
    "# ConvertMetrics to Z-Scores\n",
    "for metric in mainMetrics:\n",
    "    results_pivot[metric] = (results_pivot[metric]-results_pivot[metric].mean())/results_pivot[metric].std()\n",
    "    del metric\n",
    "\n",
    "# Build out test Frame\n",
    "testFrame = pd.DataFrame(columns={testGroup[0]:[],testGroup[0]:[]})\n",
    "\n",
    "# Get the samples and run them\n",
    "test_samples = list(itertools.combinations(results_pivot.index,r=6)) \n",
    "for sample in test_samples:\n",
    "    # Get Lists\n",
    "    test_List    = list(results_pivot[ results_pivot.index.isin(sample)].index)\n",
    "    control_List = list(results_pivot[~results_pivot.index.isin(sample)].index)\n",
    "    # Get resutlts\n",
    "    test_Results=results_pivot[results_pivot.index.isin(test_List)].mean()\n",
    "    control_Results=results_pivot[results_pivot.index.isin(control_List)].mean()\n",
    "    # Put results in DataFrame\n",
    "    appendFrame =pd.DataFrame(data={\n",
    "        'Test Members': [test_List],\n",
    "        'Control Members':[control_List],\n",
    "        'Sessions Difference':test_Results['Sessions'] - control_Results['Sessions'],\n",
    "        'AHT Difference':test_Results['AHT'] - control_Results['AHT'],\n",
    "        'SP100 Difference':test_Results['SP100'] - control_Results['SP100'],\n",
    "        'HERO Difference':test_Results['HERO'] - control_Results['HERO'],\n",
    "        'Transfers Difference':test_Results['Transfers'] - control_Results['Transfers']\n",
    "        })\n",
    "    # Append current results to existing test frame\n",
    "    testFrame=pd.concat([testFrame,appendFrame],axis=0)\n",
    "    del appendFrame, sample, test_List, control_List, test_Results, control_Results\n",
    "del test_samples, testGroup, employees, mainMetrics, results_pivot\n",
    "\n",
    "display(testFrame)\n",
    "testFrame.to_excel('ExpertGroupings.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =dfp.copy()\n",
    "df['Date']=pd.to_datetime(df['Date'])\n",
    "pivot = df.copy()\n",
    "pivot_base = pivot[pivot['Sessions']>=0]\n",
    "pivot = pd.pivot_table(pivot_base.copy(),aggfunc=max,index='Employee',values='Date').sort_values('Date')\n",
    "pivot = pd.concat((pivot,pd.pivot_table(pivot_base.copy(),aggfunc=sum,index='Employee',values='Sessions')),axis=1).sort_values('Date')\n",
    "px.bar(pd.pivot_table(df[df['Employee'].isin([549667,573190,293932,536491])].copy(),index='Date',values='Sessions',columns='Employee',aggfunc=sum)).show()\n",
    "px.line(pd.pivot_table(df.copy(),index='Date',values='Sessions',columns='Employee')).show()\n",
    "display(len(pivot),pivot)\n",
    "del df, pivot_base, pivot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
